{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f573389-89aa-4eef-b8e4-71471d296f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "root_dir = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utilities import create_model\n",
    "from utilities import TestConfiguration\n",
    "from utilities import TestDataset\n",
    "config = TestConfiguration()\n",
    "\n",
    "IMAGE_SET_NAME = 'standley_4058_test' # config.IMAGE_SET_NAME\n",
    "METADATA_FILENAME = 'words_metadata.csv' # config.METADATA_FILE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0859eb83-c121-408d-9f94-1b5456918e14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the test set locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d23c9b-bf4b-44fd-bb99-6ed91ec74afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Caught CTRL-C (signal 2) - exiting\n"
     ]
    }
   ],
   "source": [
    "# Download test set from Google Cloud Storage\n",
    "IMAGE_BUCKET = 'fmnh_datasets'\n",
    "\n",
    "storage_path = f'gs://{IMAGE_BUCKET}/{IMAGE_SET_NAME}/'\n",
    "!gsutil -m cp -r $storage_path ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0c2fe3-bc30-4872-a7fc-9d6b8e38a20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(IMAGE_SET_NAME)\n",
    "\n",
    "test_dataset = TestDataset()\n",
    "test_dataset.create_dataset(32, data_dir, METADATA_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bff72c2-b9f3-4958-add2-5af98f537d14",
   "metadata": {},
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "273f6e73-f1e3-47bb-b935-24c8207da198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://iam-model-staging/run_55_all/model/keras_metadata.pb...\n",
      "Copying gs://iam-model-staging/run_55_all/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://iam-model-staging/run_55_all/model/run_55_all-training_history.csv...\n",
      "Copying gs://iam-model-staging/run_55_all/model/variables/variables.index...    \n",
      "Copying gs://iam-model-staging/run_55_all/model/saved_model.pb...               \n",
      "\\ [5/7 files][ 83.0 MiB/ 83.0 MiB]  99% Done                                    \r"
     ]
    }
   ],
   "source": [
    "# Load model from Google Cloud Storage\n",
    "MODEL_BUCKET = 'iam-model-staging'\n",
    "MODEL_NAME = 'run_55_all'\n",
    "model_uri = f'gs://{MODEL_BUCKET}/{MODEL_NAME}/model'\n",
    "!gsutil -m cp -r $model_uri .\n",
    "prediction_model_filename = Path('./model')\n",
    "prediction_model = tf.keras.models.load_model(prediction_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65ac510-5057-4a7c-8e03-bdef5c9699ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from local filesystem\n",
    "MODEL_NAME = 'fine_tuned-prediction'\n",
    "model_location = Path(f'../transfer_learning/{MODEL_NAME}.model')\n",
    "prediction_model = tf.keras.models.load_model(model_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d94d42b7-e3e2-4022-a9f3-f00335c7b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam()\n",
    "prediction_model.compile(optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bec88a-03be-4068-a6c8-563ddc65a2ba",
   "metadata": {},
   "source": [
    "## Prediction generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f3954de-b7f9-4fc8-a44c-13e4df224852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "           label   prediction\n",
      "0             .)            \"\n",
      "1          Maxon         Maan\n",
      "2    delitescens  dillilconan\n",
      "3       radicans     Pilicana\n",
      "4           Damp         trtt\n",
      "..           ...          ...\n",
      "400     ropinqua    pospirnou\n",
      "401    macrosora        aarsu\n",
      "402          Chr          po.\n",
      "403   Polypodium    Beleuiaem\n",
      "404       plesio          Pas\n",
      "\n",
      "[405 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "prediction_results = pd.DataFrame(columns=['label', 'prediction'])\n",
    "for batch in test_dataset.test_dataset:\n",
    "    images = batch['image']\n",
    "    labels = batch['label']\n",
    "    preds = prediction_model.predict(images)\n",
    "    pred_texts = test_dataset.decode_batch_predictions(preds)\n",
    "    pred_texts = [t.replace('[UNK]', '').replace(' ', '') for t in pred_texts]\n",
    "    orig_texts = []\n",
    "    for label in labels:\n",
    "        label = tf.strings.reduce_join(test_dataset.num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "        orig_texts.append(label)\n",
    "    orig_texts = [t.replace('[UNK]', '').replace(' ', '') for t in orig_texts]\n",
    "    new_results = pd.DataFrame(zip(orig_texts, pred_texts), columns=['label', 'prediction'])\n",
    "    prediction_results = prediction_results.append(new_results, ignore_index=True)\n",
    "print(prediction_results)\n",
    "if not os.path.exists('predictions'):\n",
    "    os.makedirs('predictions')\n",
    "prediction_results.to_csv(Path('predictions', f'{MODEL_NAME}-predictions.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
