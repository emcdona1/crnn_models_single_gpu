{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0caef7f-a2f8-4534-9f60-0bbd82fa6d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 20:23:29.726133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 20:23:29.737124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 20:23:29.737807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 20:23:29.739622: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-06 20:23:29.740430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 20:23:29.741161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 20:23:29.741770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 20:23:30.241087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 20:23:30.241755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 20:23:30.242360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 20:23:30.242939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13823 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "root_dir = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from utilities import create_model\n",
    "from utilities import TrainerConfiguration\n",
    "from utilities import TrainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4244d1bf-c745-497c-b5cb-f2b4622413ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "KERNEL_SIZE=4\n",
    "ACTIVATION_FUNCTION='relu'\n",
    "LEARNING_RATE=0.001\n",
    "NUM_UNITS_DENSE=256\n",
    "NUM_UNITS_LTSM2=1024\n",
    "### run 55 parameters\n",
    "DROPOUT=0.12489316869910207\n",
    "NUM_UNITS_LTSM1=512\n",
    "### run 41 parameters\n",
    "# DROPOUT=0.1\n",
    "# NUM_UNITS_LTSM1=768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de20120-a712-4c3a-ab39-cb71c3437235",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'gs://iam-model-staging/run_55_train/model/'\n",
    "pred_model = keras.models.load_model(model_path)\n",
    "\n",
    "pred_model.save_weights(Path('checkpoints', 'pred'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700964eb-3a3e-4530-b57f-e8d89aab9841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ocr_model_v1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 400, 100, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 400, 100, 32  544         ['image[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 200, 50, 32)  0           ['Conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv2 (Conv2D)                 (None, 200, 50, 64)  32832       ['pool1[0][0]']                  \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)           (None, 100, 25, 64)  0           ['Conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 100, 1600)    0           ['pool2[0][0]']                  \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 100, 256)     409856      ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 100, 256)     0           ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 100, 1024)    3149824     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 100, 2048)   16785408    ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_layer (Dense)            (None, 100, 83)      170067      ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)            (None, 100, 83)      0           ['label[0][0]',                  \n",
      "                                                                  'dense_layer[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,548,531\n",
      "Trainable params: 20,548,531\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7f387c42c710> and <keras.engine.input_layer.InputLayer object at 0x7f387c54bb10>).\n"
     ]
    }
   ],
   "source": [
    "full_model = create_model(KERNEL_SIZE, ACTIVATION_FUNCTION, NUM_UNITS_DENSE, DROPOUT, NUM_UNITS_LTSM1, NUM_UNITS_LTSM2, LEARNING_RATE)\n",
    "full_model.load_weights(Path('checkpoints', 'pred'))\n",
    "for i in range(len(full_model.layers)):\n",
    "    full_model.layers[i].trainable=False\n",
    "full_model.layers[6].trainable = True\n",
    "full_model.layers[-1].trainable = True\n",
    "full_model.compile(keras.optimizers.Adam(learning_rate=LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a323f-f112-48cd-8ee7-222d2221bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Steyermark or Standley images\n",
    "folder = Path('images/standley_4058_train')\n",
    "metadata = Path('words_metadata.csv')\n",
    "data = TrainDataset()\n",
    "data.create_dataset(128, folder, metadata)\n",
    "\n",
    "# fit open layers\n",
    "history = full_model.fit(data.train_dataset, epochs=50, validation_data=data.validation_dataset)\n",
    "\n",
    "full_model.save('retrained.model')\n",
    "\n",
    "prediction_model = tf.keras.models.Model(\n",
    "    full_model.get_layer(name='image').input, full_model.get_layer(name='dense_layer').output\n",
    ")\n",
    "prediction_model.compile(tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
    "prediction_model.save('retrained-prediction.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72bab75-44d8-40c8-8062-d89e34fd99c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune\n",
    "full_model.trainable = True\n",
    "full_model.compile(keras.optimizers.Adam(learning_rate=1e-5))\n",
    "history_fine_tune = full_model.fit(data.train_dataset, epochs=25, validation_data=data.validation_dataset)\n",
    "\n",
    "\n",
    "full_model.save('fine_tuned.model')\n",
    "\n",
    "prediction_model = tf.keras.models.Model(\n",
    "    full_model.get_layer(name='image').input, full_model.get_layer(name='dense_layer').output\n",
    ")\n",
    "prediction_model.compile(tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
    "prediction_model.save('fine_tuned-prediction.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
